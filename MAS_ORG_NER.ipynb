{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c54a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5de68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new instance from my edu account\n",
    "NEO4J_URI      = os.getenv(\"NEO4J_URI\", \"neo4j+s://a0183311.databases.neo4j.io\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\", \"neo4j\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\", \"g9nN2A4Pp_ExSlJtescRkeZBI9BhhZulnwawbZla2oA\")\n",
    "NEO4J_CLEAR    = os.getenv(\"NEO4J_CLEAR\", \"false\").lower() == \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07c738c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆåŠŸåˆå§‹åŒ–Neo4jé©±åŠ¨ç¨‹åºã€‚\n",
      "ä»CSVä¸­å¤„ç†äº† 2866 ä¸ªèŠ‚ç‚¹å’Œ 28362 æ¡å…³ç³»ã€‚\n",
      "æ­£åœ¨åˆ›å»ºå”¯ä¸€æ€§çº¦æŸ...\n",
      "  - çº¦æŸ 'unique_organisation_id' å·²åˆ›å»ºæˆ–å·²å­˜åœ¨ã€‚\n",
      "  - çº¦æŸ 'unique_sector_id' å·²åˆ›å»ºæˆ–å·²å­˜åœ¨ã€‚\n",
      "  - çº¦æŸ 'unique_licence_id' å·²åˆ›å»ºæˆ–å·²å­˜åœ¨ã€‚\n",
      "  - çº¦æŸ 'unique_activity_id' å·²åˆ›å»ºæˆ–å·²å­˜åœ¨ã€‚\n",
      "  - çº¦æŸ 'unique_subactivity_id' å·²åˆ›å»ºæˆ–å·²å­˜åœ¨ã€‚\n",
      "çº¦æŸåˆ›å»ºå®Œæˆã€‚\n",
      "å¼€å§‹ä¸Šä¼  2866 ä¸ªèŠ‚ç‚¹...\n",
      "  - æ­£åœ¨ä¸Šä¼  2765 ä¸ª 'Organisation' èŠ‚ç‚¹...\n",
      "  - æ­£åœ¨ä¸Šä¼  5 ä¸ª 'Sector' èŠ‚ç‚¹...\n",
      "  - æ­£åœ¨ä¸Šä¼  50 ä¸ª 'Licence' èŠ‚ç‚¹...\n",
      "  - æ­£åœ¨ä¸Šä¼  38 ä¸ª 'Activity' èŠ‚ç‚¹...\n",
      "  - æ­£åœ¨ä¸Šä¼  8 ä¸ª 'SubActivity' èŠ‚ç‚¹...\n",
      "èŠ‚ç‚¹ä¸Šä¼ å®Œæˆã€‚\n",
      "å¼€å§‹ä¸Šä¼  28362 æ¡å…³ç³»...\n",
      "  - æ­£åœ¨ä¸Šä¼  8234 æ¡ 'IN_SECTOR' å…³ç³»...\n",
      "  - æ­£åœ¨ä¸Šä¼  8234 æ¡ 'HAS_LICENCE' å…³ç³»...\n",
      "  - æ­£åœ¨ä¸Šä¼  7359 æ¡ 'PERFORMS_ACTIVITY' å…³ç³»...\n",
      "  - æ­£åœ¨ä¸Šä¼  4535 æ¡ 'HAS_SUB_ACTIVITY' å…³ç³»...\n",
      "å…³ç³»ä¸Šä¼ å®Œæˆã€‚\n",
      "\n",
      "âœ… å…¨éƒ¨æ•°æ®æˆåŠŸä¸Šä¼ åˆ° Neo4j Auraï¼\n",
      "   æ€»è€—æ—¶: 123.22 ç§’ã€‚\n",
      "Neo4jé©±åŠ¨ç¨‹åºè¿æ¥å·²å…³é—­ã€‚\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1. é…ç½®æ‚¨çš„Auraæ•°æ®åº“è¿æ¥ä¿¡æ¯ ---\n",
    "# å»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡æ¥ä¿æŠ¤æ‚¨çš„å‡­è¯ï¼Œä½†ä¹Ÿå¯ä»¥ç›´æ¥åœ¨æ­¤å¤„ç¡¬ç¼–ç å­—ç¬¦ä¸²ã€‚\n",
    "# ä¾‹å¦‚: NEO4J_URI = \"neo4j+s://xxxx.databases.neo4j.io\"\n",
    "CSV_FILEPATH = \"MAS/MAS_FID_2025-06-19.csv\"\n",
    "BATCH_SIZE = 1000 # æ¯æ¬¡å‘æ•°æ®åº“å‘é€çš„æ•°æ®é‡\n",
    "\n",
    "class AuraUploader:\n",
    "    def __init__(self, uri, user, password):\n",
    "        # åˆå§‹åŒ–Neo4jé©±åŠ¨ç¨‹åº\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        print(\"æˆåŠŸåˆå§‹åŒ–Neo4jé©±åŠ¨ç¨‹åºã€‚\")\n",
    "\n",
    "    def close(self):\n",
    "        # å…³é—­é©±åŠ¨ç¨‹åºè¿æ¥\n",
    "        self.driver.close()\n",
    "        print(\"Neo4jé©±åŠ¨ç¨‹åºè¿æ¥å·²å…³é—­ã€‚\")\n",
    "\n",
    "    def process_csv_to_graph_data(self, filepath):\n",
    "        \"\"\"ä»CSVæ–‡ä»¶è¯»å–æ•°æ®å¹¶è½¬æ¢ä¸ºèŠ‚ç‚¹å’Œå…³ç³»çš„åˆ—è¡¨ã€‚\"\"\"\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"é”™è¯¯: æ–‡ä»¶ '{filepath}' æœªæ‰¾åˆ°ã€‚\")\n",
    "            return None, None\n",
    "\n",
    "        df = pd.read_csv(filepath)\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            df[col] = df[col].str.strip()\n",
    "\n",
    "        nodes = {}\n",
    "        relationships = []\n",
    "\n",
    "        def add_node(node_id, label, properties=None):\n",
    "            if isinstance(node_id, str) and node_id:\n",
    "                if node_id not in nodes:\n",
    "                    nodes[node_id] = {\"id\": node_id, \"label\": label, \"properties\": properties or {}}\n",
    "        \n",
    "        def add_relationship(source_id, target_id, rel_type):\n",
    "            if isinstance(source_id, str) and source_id and isinstance(target_id, str) and target_id:\n",
    "                relationships.append({\"source\": source_id, \"target\": target_id, \"type\": rel_type})\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            org_name = row['Organisation Name']\n",
    "            sector = row['Sector']\n",
    "            licence = row['Licence Type/Status']\n",
    "            activity = row['Activity/Business Type']\n",
    "            sub_activity = row['Sub-Activity/Product']\n",
    "\n",
    "            add_node(org_name, 'Organisation', {'name': org_name, 'address': row['Address'], 'phone': row['Phone Number'] if pd.notna(row['Phone Number']) else None, 'website': row['Website'] if pd.notna(row['Website']) else None})\n",
    "            add_node(sector, 'Sector', {'name': sector})\n",
    "            add_node(licence, 'Licence', {'name': licence})\n",
    "            add_node(activity, 'Activity', {'name': activity})\n",
    "            add_node(sub_activity, 'SubActivity', {'name': sub_activity})\n",
    "\n",
    "            add_relationship(org_name, sector, 'IN_SECTOR')\n",
    "            add_relationship(org_name, licence, 'HAS_LICENCE')\n",
    "            add_relationship(org_name, activity, 'PERFORMS_ACTIVITY')\n",
    "            if pd.notna(activity) and pd.notna(sub_activity):\n",
    "                add_relationship(activity, sub_activity, 'HAS_SUB_ACTIVITY')\n",
    "        \n",
    "        print(f\"ä»CSVä¸­å¤„ç†äº† {len(nodes)} ä¸ªèŠ‚ç‚¹å’Œ {len(relationships)} æ¡å…³ç³»ã€‚\")\n",
    "        return list(nodes.values()), relationships\n",
    "\n",
    "    def create_constraints(self):\n",
    "        \"\"\"åœ¨æ•°æ®åº“ä¸­åˆ›å»ºå”¯ä¸€æ€§çº¦æŸï¼Œä»¥ä¿è¯æ•°æ®ä¸€è‡´æ€§å¹¶æé«˜æ€§èƒ½ã€‚\"\"\"\n",
    "        print(\"æ­£åœ¨åˆ›å»ºå”¯ä¸€æ€§çº¦æŸ...\")\n",
    "        with self.driver.session() as session:\n",
    "            for label in [\"Organisation\", \"Sector\", \"Licence\", \"Activity\", \"SubActivity\"]:\n",
    "                try:\n",
    "                    session.run(f\"CREATE CONSTRAINT unique_{label.lower()}_id IF NOT EXISTS FOR (n:{label}) REQUIRE n.id IS UNIQUE\")\n",
    "                    print(f\"  - çº¦æŸ 'unique_{label.lower()}_id' å·²åˆ›å»ºæˆ–å·²å­˜åœ¨ã€‚\")\n",
    "                except Exception as e:\n",
    "                    print(f\"åˆ›å»ºçº¦æŸ {label} æ—¶å‡ºé”™: {e}\")\n",
    "        print(\"çº¦æŸåˆ›å»ºå®Œæˆã€‚\")\n",
    "\n",
    "    def upload_nodes_in_batches(self, nodes):\n",
    "        \"\"\"å°†èŠ‚ç‚¹æ•°æ®åˆ†æ‰¹ä¸Šä¼ åˆ°Neo4jã€‚\"\"\"\n",
    "        print(f\"å¼€å§‹ä¸Šä¼  {len(nodes)} ä¸ªèŠ‚ç‚¹...\")\n",
    "        query = \"\"\"\n",
    "        UNWIND $batch AS node_data\n",
    "        MERGE (n:%s {id: node_data.id})\n",
    "        SET n += node_data.properties\n",
    "        \"\"\"\n",
    "        # æŒ‰æ ‡ç­¾å¯¹èŠ‚ç‚¹è¿›è¡Œåˆ†ç»„ï¼Œä»¥ä¾¿é«˜æ•ˆæ‰¹é‡ä¸Šä¼ \n",
    "        nodes_by_label = {}\n",
    "        for node in nodes:\n",
    "            label = node['label']\n",
    "            if label not in nodes_by_label:\n",
    "                nodes_by_label[label] = []\n",
    "            # æˆ‘ä»¬åªéœ€è¦idå’Œproperties\n",
    "            nodes_by_label[label].append({'id': node['id'], 'properties': node['properties']})\n",
    "\n",
    "        with self.driver.session() as session:\n",
    "            for label, data in nodes_by_label.items():\n",
    "                print(f\"  - æ­£åœ¨ä¸Šä¼  {len(data)} ä¸ª '{label}' èŠ‚ç‚¹...\")\n",
    "                for i in range(0, len(data), BATCH_SIZE):\n",
    "                    batch = data[i:i + BATCH_SIZE]\n",
    "                    session.run(query % label, batch=batch)\n",
    "        print(\"èŠ‚ç‚¹ä¸Šä¼ å®Œæˆã€‚\")\n",
    "\n",
    "\n",
    "    def upload_relationships_in_batches(self, relationships):\n",
    "        \"\"\"å°†å…³ç³»æ•°æ®åˆ†æ‰¹ä¸Šä¼ åˆ°Neo4jã€‚\"\"\"\n",
    "        print(f\"å¼€å§‹ä¸Šä¼  {len(relationships)} æ¡å…³ç³»...\")\n",
    "        query = \"\"\"\n",
    "        UNWIND $batch AS rel_data\n",
    "        MATCH (source {id: rel_data.source})\n",
    "        MATCH (target {id: rel_data.target})\n",
    "        MERGE (source)-[:%s]->(target)\n",
    "        \"\"\"\n",
    "        # æŒ‰ç±»å‹å¯¹å…³ç³»è¿›è¡Œåˆ†ç»„\n",
    "        rels_by_type = {}\n",
    "        for rel in relationships:\n",
    "            rel_type = rel['type']\n",
    "            if rel_type not in rels_by_type:\n",
    "                rels_by_type[rel_type] = []\n",
    "            rels_by_type[rel_type].append(rel)\n",
    "\n",
    "        with self.driver.session() as session:\n",
    "            for rel_type, data in rels_by_type.items():\n",
    "                print(f\"  - æ­£åœ¨ä¸Šä¼  {len(data)} æ¡ '{rel_type}' å…³ç³»...\")\n",
    "                for i in range(0, len(data), BATCH_SIZE):\n",
    "                    batch = data[i:i + BATCH_SIZE]\n",
    "                    session.run(query % rel_type, batch=batch)\n",
    "        print(\"å…³ç³»ä¸Šä¼ å®Œæˆã€‚\")\n",
    "\n",
    "    def run_full_process(self, filepath):\n",
    "        \"\"\"æ‰§è¡Œå®Œæ•´çš„ETLæµç¨‹ï¼šå¤„ç†CSV -> åˆ›å»ºçº¦æŸ -> ä¸Šä¼ èŠ‚ç‚¹ -> ä¸Šä¼ å…³ç³»ã€‚\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        nodes, relationships = self.process_csv_to_graph_data(filepath)\n",
    "        if nodes is None:\n",
    "            return\n",
    "\n",
    "        self.create_constraints()\n",
    "        self.upload_nodes_in_batches(nodes)\n",
    "        self.upload_relationships_in_batches(relationships)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"\\nâœ… å…¨éƒ¨æ•°æ®æˆåŠŸä¸Šä¼ åˆ° Neo4j Auraï¼\")\n",
    "        print(f\"   æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’ã€‚\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # æ£€æŸ¥å‡­è¯æ˜¯å¦å·²å¡«å†™\n",
    "    if \"åœ¨æ­¤å¤„å¡«å…¥æ‚¨\" in NEO4J_URI or \"åœ¨æ­¤å¤„å¡«å…¥æ‚¨\" in NEO4J_PASSWORD:\n",
    "        print(\"é”™è¯¯ï¼šè¯·å…ˆåœ¨è„šæœ¬ä¸­å¡«å†™æ‚¨çš„ Neo4j Aura è¿æ¥å‡­è¯ (NEO4J_URI, NEO4J_PASSWORD)ã€‚\")\n",
    "    else:\n",
    "        uploader = AuraUploader(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "        uploader.run_full_process(CSV_FILEPATH)\n",
    "        uploader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "957ed280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting thefuzz\n",
      "  Downloading thefuzz-0.22.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting python-Levenshtein\n",
      "  Using cached python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.0.0 (from thefuzz)\n",
      "  Downloading rapidfuzz-3.13.0-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
      "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
      "  Downloading levenshtein-0.27.1-cp39-cp39-win_amd64.whl.metadata (3.6 kB)\n",
      "Downloading thefuzz-0.22.1-py3-none-any.whl (8.2 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp39-cp39-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.0/1.6 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 8.7 MB/s eta 0:00:00\n",
      "Using cached python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading levenshtein-0.27.1-cp39-cp39-win_amd64.whl (100 kB)\n",
      "Installing collected packages: rapidfuzz, thefuzz, Levenshtein, python-Levenshtein\n",
      "\n",
      "   ---------------------------------------- 0/4 [rapidfuzz]\n",
      "   ---------------------------------------- 4/4 [python-Levenshtein]\n",
      "\n",
      "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.13.0 thefuzz-0.22.1\n"
     ]
    }
   ],
   "source": [
    "!pip install thefuzz python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e98e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb4a9982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "from datetime import datetime # å¯¼å…¥datetimeæ¨¡å—\n",
    "from thefuzz import process as fuzzy_process\n",
    "\n",
    "# --- 1. é…ç½® ---\n",
    "PERSONNEL_CSV_PATH = \"MAS/MAS_Personnel.csv\"\n",
    "BATCH_SIZE = 500\n",
    "FUZZY_MATCH_THRESHOLD = 90\n",
    "\n",
    "class DateTimeVersionedUploader:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        # --- æ ¸å¿ƒæ”¹åŠ¨åœ¨è¿™é‡Œ ---\n",
    "        # ä¸ºæœ¬æ¬¡è¿è¡Œç”Ÿæˆä¸€ä¸ªdatetimeå¯¹è±¡ä½œä¸ºç‰ˆæœ¬æ—¶é—´æˆ³\n",
    "        self.run_timestamp = datetime.now() \n",
    "        print(f\"âœ… æˆåŠŸåˆå§‹åŒ–Neo4jé©±åŠ¨ç¨‹åºã€‚æœ¬æ¬¡è¿è¡Œçš„ç‰ˆæœ¬æ—¶é—´æˆ³: {self.run_timestamp.isoformat()}\")\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "        print(\"âœ… Neo4jé©±åŠ¨ç¨‹åºè¿æ¥å·²å…³é—­ã€‚\")\n",
    "\n",
    "    def run_cypher_query(self, query, params=None):\n",
    "        with self.driver.session() as session:\n",
    "            try:\n",
    "                result = session.run(query, params)\n",
    "                return [record for record in result]\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ CypheræŸ¥è¯¢æ‰§è¡Œå‡ºé”™: {e}\")\n",
    "                return []\n",
    "\n",
    "    def create_constraints(self):\n",
    "        print(\"\\n--- æ­¥éª¤ 1: ç¡®ä¿çº¦æŸå­˜åœ¨ ---\")\n",
    "        constraints = [\n",
    "            \"CREATE CONSTRAINT unique_organisation_id IF NOT EXISTS FOR (n:Organisation) REQUIRE n.id IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT unique_person_name IF NOT EXISTS FOR (p:Person) REQUIRE p.name IS UNIQUE\"\n",
    "        ]\n",
    "        for constraint in constraints:\n",
    "            self.run_cypher_query(constraint)\n",
    "        print(\"âœ… æ‰€æœ‰çº¦æŸå·²åˆ›å»ºæˆ–å·²å­˜åœ¨ã€‚\")\n",
    "\n",
    "    def upload_personnel_data(self, filepath):\n",
    "        print(f\"\\n--- æ­¥éª¤ 2: å¤„ç†å¹¶ä¸Šä¼ äººå‘˜æ•°æ® ({filepath}) ---\")\n",
    "        \n",
    "        # æ•°æ®å¤„ç†éƒ¨åˆ†ä¸ä¹‹å‰å®Œå…¨ç›¸åŒ\n",
    "        print(\"  - æ­£åœ¨ä»Neo4jè·å–ç°æœ‰æœºæ„åç§°...\")\n",
    "        existing_org_names = [r[\"name\"] for r in self.run_cypher_query(\"MATCH (o:Organisation) RETURN o.name AS name\")]\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"âŒ é”™è¯¯: æ–‡ä»¶ '{filepath}' æœªæ‰¾åˆ°ã€‚\")\n",
    "            return\n",
    "        personnel_df = pd.read_csv(filepath)\n",
    "        unique_csv_org_names = personnel_df['company_name'].unique()\n",
    "        name_mapping = {csv_name: fuzzy_process.extractOne(csv_name, existing_org_names)[0] \n",
    "                        for csv_name in unique_csv_org_names \n",
    "                        if fuzzy_process.extractOne(csv_name, existing_org_names)[1] >= FUZZY_MATCH_THRESHOLD}\n",
    "\n",
    "        persons_to_upload = [{'name': name} for name in personnel_df['person_name'].unique()]\n",
    "        relationships_to_upload = []\n",
    "        for _, row in personnel_df.iterrows():\n",
    "            if row['company_name'] in name_mapping:\n",
    "                relationships_to_upload.append({\n",
    "                    \"org_name\": name_mapping[row['company_name']],\n",
    "                    \"person_name\": row['person_name'],\n",
    "                    \"role\": str(row['role']).lower()})\n",
    "\n",
    "        # ä¸Šä¼ PersonèŠ‚ç‚¹\n",
    "        if persons_to_upload:\n",
    "            query_persons = \"UNWIND $batch AS p MERGE (:Person {name: p.name})\"\n",
    "            for i in range(0, len(persons_to_upload), BATCH_SIZE):\n",
    "                self.run_cypher_query(query_persons, params={\"batch\": persons_to_upload[i:i + BATCH_SIZE]})\n",
    "            print(\"  - âœ… PersonèŠ‚ç‚¹ä¸Šä¼ æˆåŠŸã€‚\")\n",
    "\n",
    "        # --- ä¸Šä¼ å…³ç³»ï¼Œå¹¶æ‰“ä¸Šdatetimeç‰ˆæœ¬æ—¶é—´æˆ³ ---\n",
    "        if relationships_to_upload:\n",
    "            query_rels = \"\"\"\n",
    "            UNWIND $batch AS rel_data\n",
    "            MATCH (o:Organisation {name: rel_data.org_name})\n",
    "            MATCH (p:Person {name: rel_data.person_name})\n",
    "            MERGE (o)-[r:HAS_OFFICER]->(p)\n",
    "            SET r.role = rel_data.role, r.last_updated_run = $timestamp\n",
    "            \"\"\"\n",
    "            for i in range(0, len(relationships_to_upload), BATCH_SIZE):\n",
    "                batch = relationships_to_upload[i:i + BATCH_SIZE]\n",
    "                self.run_cypher_query(query_rels, params={\"batch\": batch, \"timestamp\": self.run_timestamp})\n",
    "            print(\"  - âœ… HAS_OFFICERå…³ç³»åŠdatetimeç‰ˆæœ¬æˆ³ä¸Šä¼ æˆåŠŸã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a440cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"åœ¨æ­¤å¤„å¡«å…¥æ‚¨\" in NEO4J_URI or \"åœ¨æ­¤å¤„å¡«å…¥æ‚¨\" in NEO4J_PASSWORD:\n",
    "    print(\"âŒ é”™è¯¯ï¼šè¯·å…ˆåœ¨è„šæœ¬ä¸­å¡«å†™æ‚¨çš„ Neo4j Aura è¿æ¥å‡­è¯ã€‚\")\n",
    "else:\n",
    "    uploader = DateTimeVersionedUploader(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "    uploader.create_constraints()\n",
    "    uploader.upload_personnel_data(PERSONNEL_CSV_PATH)\n",
    "    uploader.close()\n",
    "    print(f\"\\nğŸ‰ æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c54a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5de68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new instance from my edu account\n",
    "NEO4J_URI      = os.getenv(\"NEO4J_URI\", \"neo4j+s://a0183311.databases.neo4j.io\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\", \"neo4j\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\", \"g9nN2A4Pp_ExSlJtescRkeZBI9BhhZulnwawbZla2oA\")\n",
    "NEO4J_CLEAR    = os.getenv(\"NEO4J_CLEAR\", \"false\").lower() == \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07c738c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功初始化Neo4j驱动程序。\n",
      "从CSV中处理了 2866 个节点和 28362 条关系。\n",
      "正在创建唯一性约束...\n",
      "  - 约束 'unique_organisation_id' 已创建或已存在。\n",
      "  - 约束 'unique_sector_id' 已创建或已存在。\n",
      "  - 约束 'unique_licence_id' 已创建或已存在。\n",
      "  - 约束 'unique_activity_id' 已创建或已存在。\n",
      "  - 约束 'unique_subactivity_id' 已创建或已存在。\n",
      "约束创建完成。\n",
      "开始上传 2866 个节点...\n",
      "  - 正在上传 2765 个 'Organisation' 节点...\n",
      "  - 正在上传 5 个 'Sector' 节点...\n",
      "  - 正在上传 50 个 'Licence' 节点...\n",
      "  - 正在上传 38 个 'Activity' 节点...\n",
      "  - 正在上传 8 个 'SubActivity' 节点...\n",
      "节点上传完成。\n",
      "开始上传 28362 条关系...\n",
      "  - 正在上传 8234 条 'IN_SECTOR' 关系...\n",
      "  - 正在上传 8234 条 'HAS_LICENCE' 关系...\n",
      "  - 正在上传 7359 条 'PERFORMS_ACTIVITY' 关系...\n",
      "  - 正在上传 4535 条 'HAS_SUB_ACTIVITY' 关系...\n",
      "关系上传完成。\n",
      "\n",
      "✅ 全部数据成功上传到 Neo4j Aura！\n",
      "   总耗时: 123.22 秒。\n",
      "Neo4j驱动程序连接已关闭。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1. 配置您的Aura数据库连接信息 ---\n",
    "# 建议使用环境变量来保护您的凭证，但也可以直接在此处硬编码字符串。\n",
    "# 例如: NEO4J_URI = \"neo4j+s://xxxx.databases.neo4j.io\"\n",
    "CSV_FILEPATH = \"MAS/MAS_FID_2025-06-19.csv\"\n",
    "BATCH_SIZE = 1000 # 每次向数据库发送的数据量\n",
    "\n",
    "class AuraUploader:\n",
    "    def __init__(self, uri, user, password):\n",
    "        # 初始化Neo4j驱动程序\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        print(\"成功初始化Neo4j驱动程序。\")\n",
    "\n",
    "    def close(self):\n",
    "        # 关闭驱动程序连接\n",
    "        self.driver.close()\n",
    "        print(\"Neo4j驱动程序连接已关闭。\")\n",
    "\n",
    "    def process_csv_to_graph_data(self, filepath):\n",
    "        \"\"\"从CSV文件读取数据并转换为节点和关系的列表。\"\"\"\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"错误: 文件 '{filepath}' 未找到。\")\n",
    "            return None, None\n",
    "\n",
    "        df = pd.read_csv(filepath)\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            df[col] = df[col].str.strip()\n",
    "\n",
    "        nodes = {}\n",
    "        relationships = []\n",
    "\n",
    "        def add_node(node_id, label, properties=None):\n",
    "            if isinstance(node_id, str) and node_id:\n",
    "                if node_id not in nodes:\n",
    "                    nodes[node_id] = {\"id\": node_id, \"label\": label, \"properties\": properties or {}}\n",
    "        \n",
    "        def add_relationship(source_id, target_id, rel_type):\n",
    "            if isinstance(source_id, str) and source_id and isinstance(target_id, str) and target_id:\n",
    "                relationships.append({\"source\": source_id, \"target\": target_id, \"type\": rel_type})\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            org_name = row['Organisation Name']\n",
    "            sector = row['Sector']\n",
    "            licence = row['Licence Type/Status']\n",
    "            activity = row['Activity/Business Type']\n",
    "            sub_activity = row['Sub-Activity/Product']\n",
    "\n",
    "            add_node(org_name, 'Organisation', {'name': org_name, 'address': row['Address'], 'phone': row['Phone Number'] if pd.notna(row['Phone Number']) else None, 'website': row['Website'] if pd.notna(row['Website']) else None})\n",
    "            add_node(sector, 'Sector', {'name': sector})\n",
    "            add_node(licence, 'Licence', {'name': licence})\n",
    "            add_node(activity, 'Activity', {'name': activity})\n",
    "            add_node(sub_activity, 'SubActivity', {'name': sub_activity})\n",
    "\n",
    "            add_relationship(org_name, sector, 'IN_SECTOR')\n",
    "            add_relationship(org_name, licence, 'HAS_LICENCE')\n",
    "            add_relationship(org_name, activity, 'PERFORMS_ACTIVITY')\n",
    "            if pd.notna(activity) and pd.notna(sub_activity):\n",
    "                add_relationship(activity, sub_activity, 'HAS_SUB_ACTIVITY')\n",
    "        \n",
    "        print(f\"从CSV中处理了 {len(nodes)} 个节点和 {len(relationships)} 条关系。\")\n",
    "        return list(nodes.values()), relationships\n",
    "\n",
    "    def create_constraints(self):\n",
    "        \"\"\"在数据库中创建唯一性约束，以保证数据一致性并提高性能。\"\"\"\n",
    "        print(\"正在创建唯一性约束...\")\n",
    "        with self.driver.session() as session:\n",
    "            for label in [\"Organisation\", \"Sector\", \"Licence\", \"Activity\", \"SubActivity\"]:\n",
    "                try:\n",
    "                    session.run(f\"CREATE CONSTRAINT unique_{label.lower()}_id IF NOT EXISTS FOR (n:{label}) REQUIRE n.id IS UNIQUE\")\n",
    "                    print(f\"  - 约束 'unique_{label.lower()}_id' 已创建或已存在。\")\n",
    "                except Exception as e:\n",
    "                    print(f\"创建约束 {label} 时出错: {e}\")\n",
    "        print(\"约束创建完成。\")\n",
    "\n",
    "    def upload_nodes_in_batches(self, nodes):\n",
    "        \"\"\"将节点数据分批上传到Neo4j。\"\"\"\n",
    "        print(f\"开始上传 {len(nodes)} 个节点...\")\n",
    "        query = \"\"\"\n",
    "        UNWIND $batch AS node_data\n",
    "        MERGE (n:%s {id: node_data.id})\n",
    "        SET n += node_data.properties\n",
    "        \"\"\"\n",
    "        # 按标签对节点进行分组，以便高效批量上传\n",
    "        nodes_by_label = {}\n",
    "        for node in nodes:\n",
    "            label = node['label']\n",
    "            if label not in nodes_by_label:\n",
    "                nodes_by_label[label] = []\n",
    "            # 我们只需要id和properties\n",
    "            nodes_by_label[label].append({'id': node['id'], 'properties': node['properties']})\n",
    "\n",
    "        with self.driver.session() as session:\n",
    "            for label, data in nodes_by_label.items():\n",
    "                print(f\"  - 正在上传 {len(data)} 个 '{label}' 节点...\")\n",
    "                for i in range(0, len(data), BATCH_SIZE):\n",
    "                    batch = data[i:i + BATCH_SIZE]\n",
    "                    session.run(query % label, batch=batch)\n",
    "        print(\"节点上传完成。\")\n",
    "\n",
    "\n",
    "    def upload_relationships_in_batches(self, relationships):\n",
    "        \"\"\"将关系数据分批上传到Neo4j。\"\"\"\n",
    "        print(f\"开始上传 {len(relationships)} 条关系...\")\n",
    "        query = \"\"\"\n",
    "        UNWIND $batch AS rel_data\n",
    "        MATCH (source {id: rel_data.source})\n",
    "        MATCH (target {id: rel_data.target})\n",
    "        MERGE (source)-[:%s]->(target)\n",
    "        \"\"\"\n",
    "        # 按类型对关系进行分组\n",
    "        rels_by_type = {}\n",
    "        for rel in relationships:\n",
    "            rel_type = rel['type']\n",
    "            if rel_type not in rels_by_type:\n",
    "                rels_by_type[rel_type] = []\n",
    "            rels_by_type[rel_type].append(rel)\n",
    "\n",
    "        with self.driver.session() as session:\n",
    "            for rel_type, data in rels_by_type.items():\n",
    "                print(f\"  - 正在上传 {len(data)} 条 '{rel_type}' 关系...\")\n",
    "                for i in range(0, len(data), BATCH_SIZE):\n",
    "                    batch = data[i:i + BATCH_SIZE]\n",
    "                    session.run(query % rel_type, batch=batch)\n",
    "        print(\"关系上传完成。\")\n",
    "\n",
    "    def run_full_process(self, filepath):\n",
    "        \"\"\"执行完整的ETL流程：处理CSV -> 创建约束 -> 上传节点 -> 上传关系。\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        nodes, relationships = self.process_csv_to_graph_data(filepath)\n",
    "        if nodes is None:\n",
    "            return\n",
    "\n",
    "        self.create_constraints()\n",
    "        self.upload_nodes_in_batches(nodes)\n",
    "        self.upload_relationships_in_batches(relationships)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"\\n✅ 全部数据成功上传到 Neo4j Aura！\")\n",
    "        print(f\"   总耗时: {end_time - start_time:.2f} 秒。\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 检查凭证是否已填写\n",
    "    if \"在此处填入您\" in NEO4J_URI or \"在此处填入您\" in NEO4J_PASSWORD:\n",
    "        print(\"错误：请先在脚本中填写您的 Neo4j Aura 连接凭证 (NEO4J_URI, NEO4J_PASSWORD)。\")\n",
    "    else:\n",
    "        uploader = AuraUploader(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "        uploader.run_full_process(CSV_FILEPATH)\n",
    "        uploader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "957ed280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting thefuzz\n",
      "  Downloading thefuzz-0.22.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting python-Levenshtein\n",
      "  Using cached python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.0.0 (from thefuzz)\n",
      "  Downloading rapidfuzz-3.13.0-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
      "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
      "  Downloading levenshtein-0.27.1-cp39-cp39-win_amd64.whl.metadata (3.6 kB)\n",
      "Downloading thefuzz-0.22.1-py3-none-any.whl (8.2 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp39-cp39-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.0/1.6 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 8.7 MB/s eta 0:00:00\n",
      "Using cached python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading levenshtein-0.27.1-cp39-cp39-win_amd64.whl (100 kB)\n",
      "Installing collected packages: rapidfuzz, thefuzz, Levenshtein, python-Levenshtein\n",
      "\n",
      "   ---------------------------------------- 0/4 [rapidfuzz]\n",
      "   ---------------------------------------- 4/4 [python-Levenshtein]\n",
      "\n",
      "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.13.0 thefuzz-0.22.1\n"
     ]
    }
   ],
   "source": [
    "!pip install thefuzz python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e98e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb4a9982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "from datetime import datetime # 导入datetime模块\n",
    "from thefuzz import process as fuzzy_process\n",
    "\n",
    "# --- 1. 配置 ---\n",
    "PERSONNEL_CSV_PATH = \"MAS/MAS_Personnel.csv\"\n",
    "BATCH_SIZE = 500\n",
    "FUZZY_MATCH_THRESHOLD = 90\n",
    "\n",
    "class DateTimeVersionedUploader:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        # --- 核心改动在这里 ---\n",
    "        # 为本次运行生成一个datetime对象作为版本时间戳\n",
    "        self.run_timestamp = datetime.now() \n",
    "        print(f\"✅ 成功初始化Neo4j驱动程序。本次运行的版本时间戳: {self.run_timestamp.isoformat()}\")\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "        print(\"✅ Neo4j驱动程序连接已关闭。\")\n",
    "\n",
    "    def run_cypher_query(self, query, params=None):\n",
    "        with self.driver.session() as session:\n",
    "            try:\n",
    "                result = session.run(query, params)\n",
    "                return [record for record in result]\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Cypher查询执行出错: {e}\")\n",
    "                return []\n",
    "\n",
    "    def create_constraints(self):\n",
    "        print(\"\\n--- 步骤 1: 确保约束存在 ---\")\n",
    "        constraints = [\n",
    "            \"CREATE CONSTRAINT unique_organisation_id IF NOT EXISTS FOR (n:Organisation) REQUIRE n.id IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT unique_person_name IF NOT EXISTS FOR (p:Person) REQUIRE p.name IS UNIQUE\"\n",
    "        ]\n",
    "        for constraint in constraints:\n",
    "            self.run_cypher_query(constraint)\n",
    "        print(\"✅ 所有约束已创建或已存在。\")\n",
    "\n",
    "    def upload_personnel_data(self, filepath):\n",
    "        print(f\"\\n--- 步骤 2: 处理并上传人员数据 ({filepath}) ---\")\n",
    "        \n",
    "        # 数据处理部分与之前完全相同\n",
    "        print(\"  - 正在从Neo4j获取现有机构名称...\")\n",
    "        existing_org_names = [r[\"name\"] for r in self.run_cypher_query(\"MATCH (o:Organisation) RETURN o.name AS name\")]\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"❌ 错误: 文件 '{filepath}' 未找到。\")\n",
    "            return\n",
    "        personnel_df = pd.read_csv(filepath)\n",
    "        unique_csv_org_names = personnel_df['company_name'].unique()\n",
    "        name_mapping = {csv_name: fuzzy_process.extractOne(csv_name, existing_org_names)[0] \n",
    "                        for csv_name in unique_csv_org_names \n",
    "                        if fuzzy_process.extractOne(csv_name, existing_org_names)[1] >= FUZZY_MATCH_THRESHOLD}\n",
    "\n",
    "        persons_to_upload = [{'name': name} for name in personnel_df['person_name'].unique()]\n",
    "        relationships_to_upload = []\n",
    "        for _, row in personnel_df.iterrows():\n",
    "            if row['company_name'] in name_mapping:\n",
    "                relationships_to_upload.append({\n",
    "                    \"org_name\": name_mapping[row['company_name']],\n",
    "                    \"person_name\": row['person_name'],\n",
    "                    \"role\": str(row['role']).lower()})\n",
    "\n",
    "        # 上传Person节点\n",
    "        if persons_to_upload:\n",
    "            query_persons = \"UNWIND $batch AS p MERGE (:Person {name: p.name})\"\n",
    "            for i in range(0, len(persons_to_upload), BATCH_SIZE):\n",
    "                self.run_cypher_query(query_persons, params={\"batch\": persons_to_upload[i:i + BATCH_SIZE]})\n",
    "            print(\"  - ✅ Person节点上传成功。\")\n",
    "\n",
    "        # --- 上传关系，并打上datetime版本时间戳 ---\n",
    "        if relationships_to_upload:\n",
    "            query_rels = \"\"\"\n",
    "            UNWIND $batch AS rel_data\n",
    "            MATCH (o:Organisation {name: rel_data.org_name})\n",
    "            MATCH (p:Person {name: rel_data.person_name})\n",
    "            MERGE (o)-[r:HAS_OFFICER]->(p)\n",
    "            SET r.role = rel_data.role, r.last_updated_run = $timestamp\n",
    "            \"\"\"\n",
    "            for i in range(0, len(relationships_to_upload), BATCH_SIZE):\n",
    "                batch = relationships_to_upload[i:i + BATCH_SIZE]\n",
    "                self.run_cypher_query(query_rels, params={\"batch\": batch, \"timestamp\": self.run_timestamp})\n",
    "            print(\"  - ✅ HAS_OFFICER关系及datetime版本戳上传成功。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a440cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"在此处填入您\" in NEO4J_URI or \"在此处填入您\" in NEO4J_PASSWORD:\n",
    "    print(\"❌ 错误：请先在脚本中填写您的 Neo4j Aura 连接凭证。\")\n",
    "else:\n",
    "    uploader = DateTimeVersionedUploader(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "    uploader.create_constraints()\n",
    "    uploader.upload_personnel_data(PERSONNEL_CSV_PATH)\n",
    "    uploader.close()\n",
    "    print(f\"\\n🎉 流程执行完毕！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
